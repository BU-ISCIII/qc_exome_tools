# [parse\_hsmetrics.py](https://github.com/BU-ISCIII/qc_exome_tools/blob/develop/scripts/parse_hsmetrics.py)

## Description:
Python script to create a Dictionary and csv file with the [statistics of hsmetrics.out files](https://github.com/BU-ISCIII/exome_pipeline/tree/develop/templates_TRIO_service/stats/bamstats) obtained with [Picard CollectHsMetrics](https://broadinstitute.github.io/picard/picard-metric-definitions.html#HsMetrics) in the [BU-ISCIII-exome-pipeline](https://github.com/BU-ISCIII/exome_pipeline):


Metrics generated by CollectHsMetrics for the analysis of target-capture sequencing experiments. The metrics in this class fall broadly into three categories:

*   Basic sequencing metrics that are either generated as a baseline against which to evaluate other metrics or because they are used in the calculation of other metrics. This includes things like the genome size, the number of reads, the number of aligned reads etc.
*   Metrics that are intended for evaluating the performance of the wet-lab assay that generated the data. This group includes metrics like the number of bases mapping on/off/near baits, %selected, fold 80 base penalty, hs library size and the hs penalty metrics. These metrics are calculated prior to some of the filters are applied (e.g. low mapping quality reads, low base quality bases and bases overlapping in the middle of paired-end reads are all counted).
*   Metrics for assessing target coverage as a proxy for how well the data is likely to perform in downstream applications like variant calling. This group includes metrics like mean target coverage, the percentage of bases reaching various coverage levels, and the percentage of bases excluded by various filters. These metrics are computed using the strictest subset of the data, after all filters have been applied.

<table>

<tbody>

<tr>

<th>Field</th>

<th>Description</th>

</tr>

<tr>

<td>BAIT_SET</td>

<td>The name of the bait set used in the hybrid selection.</td>

</tr>

<tr>

<td>GENOME_SIZE</td>

<td>The number of bases in the reference genome used for alignment.</td>

</tr>

<tr>

<td>BAIT_TERRITORY</td>

<td>The number of bases which are localized to one or more baits.</td>

</tr>

<tr>

<td>TARGET_TERRITORY</td>

<td>The unique number of target bases in the experiment, where the target sequence is usually exons etc.</td>

</tr>

<tr>

<td>BAIT_DESIGN_EFFICIENCY</td>

<td>The ratio of TARGET_TERRITORY/BAIT_TERRITORY. A value of 1 indicates a perfect design efficiency, while a valud of 0.5 indicates that half of bases within the bait region are not within the target region.</td>

</tr>

<tr>

<td>TOTAL_READS</td>

<td>The total number of reads in the SAM or BAM file examined.</td>

</tr>

<tr>

<td>PF_READS</td>

<td>The total number of reads that pass the vendor's filter.</td>

</tr>

<tr>

<td>PF_UNIQUE_READS</td>

<td>The number of PF reads that are not marked as duplicates.</td>

</tr>

<tr>

<td>PCT_PF_READS</td>

<td>The fraction of reads passing the vendor's filter, PF_READS/TOTAL_READS.</td>

</tr>

<tr>

<td>PCT_PF_UQ_READS</td>

<td>The fraction of PF_UNIQUE_READS from the TOTAL_READS, PF_UNIQUE_READS/TOTAL_READS.</td>

</tr>

<tr>

<td>PF_UQ_READS_ALIGNED</td>

<td>The number of PF_UNIQUE_READS that aligned to the reference genome with a mapping score > 0.</td>

</tr>

<tr>

<td>PCT_PF_UQ_READS_ALIGNED</td>

<td>The fraction of PF_UQ_READS_ALIGNED from the total number of PF reads.</td>

</tr>

<tr>

<td>PF_UQ_BASES_ALIGNED</td>

<td>The number of bases in the PF_UQ_READS_ALIGNED reads. Accounts for clipping and gaps.</td>

</tr>

<tr>

<td>ON_BAIT_BASES</td>

<td>The number of PF_BASES_ALIGNED that are mapped to the baited regions of the genome.</td>

</tr>

<tr>

<td>NEAR_BAIT_BASES</td>

<td>The number of PF_BASES_ALIGNED that are mapped to within a fixed interval containing a baited region, but not within the baited section per se.</td>

</tr>

<tr>

<td>OFF_BAIT_BASES</td>

<td>The number of PF_BASES_ALIGNED that are mapped away from any baited region.</td>

</tr>

<tr>

<td>ON_TARGET_BASES</td>

<td>The number of PF_BASES_ALIGNED that are mapped to a targeted region of the genome.</td>

</tr>

<tr>

<td>PCT_SELECTED_BASES</td>

<td>The fraction of PF_BASES_ALIGNED located on or near a baited region (ON_BAIT_BASES + NEAR_BAIT_BASES)/PF_BASES_ALIGNED.</td>

</tr>

<tr>

<td>PCT_OFF_BAIT</td>

<td>The fraction of PF_BASES_ALIGNED that are mapped away from any baited region, OFF_BAIT_BASES/PF_BASES_ALIGNED.</td>

</tr>

<tr>

<td>ON_BAIT_VS_SELECTED</td>

<td>The fraction of bases on or near baits that are covered by baits, ON_BAIT_BASES/(ON_BAIT_BASES + NEAR_BAIT_BASES).</td>

</tr>

<tr>

<td>MEAN_BAIT_COVERAGE</td>

<td>The mean coverage of all baits in the experiment.</td>

</tr>

<tr>

<td>MEAN_TARGET_COVERAGE</td>

<td>The mean coverage of a target region.</td>

</tr>

<tr>

<td>PCT_USABLE_BASES_ON_BAIT</td>

<td>The number of aligned, de-duped, on-bait bases out of the PF bases available.</td>

</tr>

<tr>

<td>PCT_USABLE_BASES_ON_TARGET</td>

<td>The number of aligned, de-duped, on-target bases out of all of the PF bases available.</td>

</tr>

<tr>

<td>FOLD_ENRICHMENT</td>

<td>The fold by which the baited region has been amplified above genomic background.</td>

</tr>

<tr>

<td>ZERO_CVG_TARGETS_PCT</td>

<td>The fraction of targets that did not reach coverage=1 over any base.</td>

</tr>

<tr>

<td>FOLD_80_BASE_PENALTY</td>

<td>The fold over-coverage necessary to raise 80% of bases in "non-zero-cvg" targets to the mean coverage level in those targets.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_2X</td>

<td>The fraction of all target bases achieving 2X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_10X</td>

<td>The fraction of all target bases achieving 10X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_20X</td>

<td>The fraction of all target bases achieving 20X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_30X</td>

<td>The fraction of all target bases achieving 30X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_40X</td>

<td>The fraction of all target bases achieving 40X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_50X</td>

<td>The fraction of all target bases achieving 50X or greater coverage.</td>

</tr>

<tr>

<td>PCT_TARGET_BASES_100X</td>

<td>The fraction of all target bases achieving 100X or greater coverage.</td>

</tr>

<tr>

<td>HS_LIBRARY_SIZE</td>

<td>The estimated number of unique molecules in the selected part of the library.</td>

</tr>

<tr>

<td>HS_PENALTY_10X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 10X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 10X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 10 * HS_PENALTY_10X.</td>

</tr>

<tr>

<td>HS_PENALTY_20X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 20X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 20X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 20 * HS_PENALTY_20X.</td>

</tr>

<tr>

<td>HS_PENALTY_30X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 30X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 30X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 30 * HS_PENALTY_30X.</td>

</tr>

<tr>

<td>HS_PENALTY_40X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 40X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 40X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 40 * HS_PENALTY_40X.</td>

</tr>

<tr>

<td>HS_PENALTY_50X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 50X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 50X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 50 * HS_PENALTY_50X.</td>

</tr>

<tr>

<td>HS_PENALTY_100X</td>

<td>The "hybrid selection penalty" incurred to get 80% of target bases to 100X. This metric should be interpreted as: if I have a design with 10 megabases of target, and want to get 100X coverage I need to sequence until PF_ALIGNED_BASES = 10^7 * 100 * HS_PENALTY_100X.</td>

</tr>

<tr>

<td>AT_DROPOUT</td>

<td>A measure of how undercovered <= 50% GC regions are relative to the mean. For each GC bin [0..50] we calculate a = % of target territory, and b = % of aligned reads aligned to these targets. AT DROPOUT is then abs(sum(a-b when a-b < 0)). E.g. if the value is 5% this implies that 5% of total reads that should have mapped to GC<=50% regions mapped elsewhere.</td>

</tr>

<tr>

<td>GC_DROPOUT</td>

<td>A measure of how undercovered >= 50% GC regions are relative to the mean. For each GC bin [50..100] we calculate a = % of target territory, and b = % of aligned reads aligned to these targets. GC DROPOUT is then abs(sum(a-b when a-b < 0)). E.g. if the value is 5% this implies that 5% of total reads that should have mapped to GC>=50% regions mapped elsewhere.</td>

</tr>

</tbody>

</table>

</section>

```
##Example for runnig Picard CollectHsMetrics in SGE cluster:

qsub -V -b y -j y -l h_vmem=15g -cwd -N PICARDHSMETRICS.sample -q all.q
java -Xmx10g -jar /opt/picard-tools/picard-tools-1.140/picard.jar CalculateHsMetrics 
BI= /path/to/capture_targets.interval_list 
TI= /path/to/panel-targets.interval_list 
I=/path/to//sample.woduplicates.bam 
O=sample_hsMetrics.out VALIDATION_STRINGENCY='LENIENT'

```



## Input files:

 hsmetrics.out files including path where are stored 

```
--input /path/to/*hsmetrics.out
        
```
  
## Output files:

A dictionary converted to csv file with the hsMetrics statistics:

```
--out /path/to/Results/dic_hsMetrics_all.csv
``` 

Column names of the obtained csv file are:


* sample
* hsMetrics\_AT\_DROPOUT
* hsMetrics\_BAIT\_DESIGN\_EFFICIENCY
* hsMetrics\_BAIT\_SET
* hsMetrics\_BAIT\_TERRITORY
* hsMetrics\_FOLD\_80\_BASE\_PENALTY
* hsMetrics\_FOLD\_ENRICHMENT
* hsMetrics\_GC\_DROPOUT
* hsMetrics\_GENOME\_SIZE
* hsMetrics\_HS\_LIBRARY\_SIZE
* hsMetrics\_HS\_PENALTY\_100X
* hsMetrics\_HS_PENALTY\_10X
* hsMetrics\_HS\_PENALTY\_20X
* hsMetrics_HS\_PENALTY\_30X
* hsMetrics\_HS_PENALTY\_40X
* hsMetrics\_HS_PENALTY\_50X
* hsMetrics\_LIBRARY
* hsMetrics\_MEAN\_BAIT\_COVERAGE
* hsMetrics\_MEAN\_TARGET\_COVERAGE
* hsMetrics\_NEAR\_BAIT\_BASES
* hsMetrics\_OFF\_BAIT\_BASES
* hsMetrics\_ON\_BAIT\_BASES
* hsMetrics\_ON\_BAIT\_VS\_SELECTED
* hsMetrics\_ON\_TARGET\_BASES
* hsMetrics\_PCT\_OFF\_BAIT
* hsMetrics\_PCT\_PF\_READS
* hsMetrics\_PCT\_PF\_UQ\_READS
* hsMetrics\_PCT\_PF\_UQ\_READS\_ALIGNED
* hsMetrics\_PCT\_SELECTED\_BASES
* hsMetrics\_PCT\_TARGET\_BASES\_100
* hsMetrics\_PCT\_TARGET\_BASES\_10X
* hsMetrics\_PCT\_TARGET\_BASES\_20X
* hsMetrics\_PCT\_TARGET\_BASES\_2X
* hsMetrics\_PCT\_TARGET\_BASES_30X
* hsMetrics\_PCT\_TARGET\_BASES\_40X
* hsMetrics\_PCT\_TARGET\_BASES\_50X
* hsMetrics\_PCT\_USABLE\_BASES\_ON\_BAIT
* hsMetrics\_PCT\_USABLE\_BASES\_ON\_TARGET
* hsMetrics\_PF\_READS
* hsMetrics\_PF\_UNIQUE_READS
* hsMetrics\_PF_UQ_BASES_ALIGNED
* hsMetrics\_PF\_UQ\_READS\_ALIGNED
* hsMetrics\_READ\_GROUP
* hsMetrics\_SAMPLE
* hsMetrics\_TARGET\_TERRITORY
* hsMetrics\_TOTAL\_READS
* hsMetrics\_ZERO\_CVG\_TARGETS\_PCT



## Example

For running in a local computer:

```
python3 /path/to/parse_hsmetrics.py
--input /path/to/hsmetrics/*.out
--out /path/to/RESULTS/dic_hsmetrics.csv

```
 

For submission to the SGE cluster:

```
qsub -V -b y -j y -cwd -N "parse_hsmetrics_date" -q all.q python3 /path/to/parse_hsmetrics.py
--input /path/to/hsmetrics/*.out
--out /path/to/RESULTS/dic_hsmetrics.csv

```
   